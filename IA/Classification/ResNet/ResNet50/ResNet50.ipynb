{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet import ResNet50\n",
    "from keras.preprocessing import image\n",
    "import keras.utils as image\n",
    "from keras.applications.resnet import preprocess_input, decode_predictions\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of classes\n",
    "num_classes = 11\n",
    "\n",
    "# Load the ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Add a fully connected layer with a softmax activation\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Define the full model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the base model's layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing function\n",
    "def preprocess_function(img):\n",
    "    img = image.img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# Define the data generators\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_function)\n",
    "val_datagen = ImageDataGenerator(preprocessing_function=preprocess_function)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entraînement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"resnet50_model.h5\", monitor='accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early = EarlyStopping(monitor='accuracy', min_delta=0, patience=4, verbose=1, mode='auto')\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "callbacks_list = [checkpoint, early, reduce_lr]\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_datagen.flow_from_directory('DataResizeSplit/Train',\n",
    "                                                      target_size=(224,224),\n",
    "                                                      batch_size=32,\n",
    "                                                      class_mode='categorical'),\n",
    "                                                      epochs=15,\n",
    "                    validation_data=val_datagen.flow_from_directory('DataResizeSplit/Test',\n",
    "                                                                    target_size=(224,224),\n",
    "                                                                    batch_size=32,\n",
    "                                                                    class_mode='categorical'),\n",
    "                    verbose=1,\n",
    "                    callbacks=callbacks_list)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracé des courbes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the accuracy and loss curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['accuracy'], 'r', linewidth=2.0)\n",
    "plt.plot(history.history['val_accuracy'], 'b', linewidth=2.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=18)\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.title('Accuracy Curves', fontsize=16)\n",
    "plt.savefig('accuracy__curves_res50.png')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'], 'r', linewidth=2.0)\n",
    "plt.plot(history.history['val_loss'], 'b', linewidth=2.0)\n",
    "plt.legend(['Training Loss', 'Validation Loss'], fontsize=18)\n",
    "plt.xlabel('Epoch', fontsize=16)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.title('Loss Curves', fontsize=16)\n",
    "plt.savefig('loss_curves_res50.png')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
